{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import folium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datasets\n",
    "df = pd.read_csv('../Traffic_Crashes_-_Crashes.csv')\n",
    "df_people = pd.read_csv('../Traffic_Crashes_-_People.csv')\n",
    "df_vehicles = pd.read_csv('../Traffic_Crashes_-_Vehicles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Datasets on the Crash_Record_ID Column\n",
    "df_merge = pd.merge(df, df_vehicles, on='CRASH_RECORD_ID').reset_index()\n",
    "df_merge_2 = pd.merge(df_merge, df_people, on='CRASH_RECORD_ID').reset_index()\n",
    "#dropping dupllicates(basically only having one instance of the crashID on there)\n",
    "df_dropped= df_merge_2.drop_duplicates(subset=['CRASH_RECORD_ID'], keep='first')\n",
    "#Taking only necessary columns\n",
    "columns = ['CRASH_RECORD_ID', 'RD_NO_x', 'CRASH_DATE_x', 'POSTED_SPEED_LIMIT', 'TRAFFIC_CONTROL_DEVICE', 'DEVICE_CONDITION', 'WEATHER_CONDITION', 'LIGHTING_CONDITION', 'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE', 'LANE_CNT', 'ALIGNMENT', 'ROADWAY_SURFACE_COND', 'ROAD_DEFECT', 'CRASH_TYPE', 'INTERSECTION_RELATED_I', 'NOT_RIGHT_OF_WAY_I', 'HIT_AND_RUN_I', 'DAMAGE', 'PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE', 'STREET_NO', 'STREET_DIRECTION', 'STREET_NAME',  'DOORING_I', 'WORK_ZONE_I', 'WORK_ZONE_TYPE', 'WORKERS_PRESENT_I', 'NUM_UNITS', 'MOST_SEVERE_INJURY', 'INJURIES_TOTAL', 'INJURIES_FATAL', 'INJURIES_INCAPACITATING', 'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT', 'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN', 'CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH', 'LATITUDE', 'LONGITUDE', 'LOCATION', 'RD_NO_y', 'UNIT_NO', 'UNIT_TYPE', 'NUM_PASSENGERS', 'VEHICLE_ID_x', 'CMRC_VEH_I', 'MAKE', 'MODEL', 'VEHICLE_YEAR', 'VEHICLE_DEFECT', 'VEHICLE_TYPE', 'TRAVEL_DIRECTION', 'MANEUVER', 'OCCUPANT_CNT', 'EXCEED_SPEED_LIMIT_I', 'FIRST_CONTACT_POINT', 'PERSON_TYPE', 'CITY', 'STATE', 'ZIPCODE', 'SEX', 'AGE',  'AIRBAG_DEPLOYED', 'EJECTION', 'INJURY_CLASSIFICATION', 'DRIVER_VISION','PHYSICAL_CONDITION', 'PEDPEDAL_ACTION', 'PEDPEDAL_VISIBILITY', 'PEDPEDAL_LOCATION', 'BAC_RESULT', 'BAC_RESULT VALUE', 'CELL_PHONE_USE']\n",
    "df_comb = df_dropped[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the Year from the date column\n",
    "df_comb['date'] = pd.to_datetime(df_comb['CRASH_DATE_x'])\n",
    "df_comb['Crash_year'] = df_comb['date'].apply(lambda date: date.year)\n",
    "#only accidents with the driver\n",
    "df_driver = df_comb[df_comb['PERSON_TYPE']=='DRIVER']\n",
    "#necessary columns\n",
    "new_columns = ['CRASH_RECORD_ID', 'CRASH_DATE_x', 'POSTED_SPEED_LIMIT',\n",
    "       'TRAFFIC_CONTROL_DEVICE', 'DEVICE_CONDITION', 'WEATHER_CONDITION',\n",
    "       'LIGHTING_CONDITION', 'FIRST_CRASH_TYPE', 'TRAFFICWAY_TYPE',\n",
    "       'ALIGNMENT', 'ROADWAY_SURFACE_COND', 'ROAD_DEFECT', 'CRASH_TYPE',\n",
    "       'DAMAGE', 'PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE','NUM_UNITS',\n",
    "       'MOST_SEVERE_INJURY', 'INJURIES_TOTAL', 'INJURIES_FATAL',\n",
    "       'INJURIES_INCAPACITATING', 'INJURIES_NON_INCAPACITATING',\n",
    "       'INJURIES_REPORTED_NOT_EVIDENT','CRASH_HOUR', 'CRASH_DAY_OF_WEEK', 'CRASH_MONTH',\n",
    "       'LATITUDE', 'LONGITUDE', 'MAKE', 'MODEL',\n",
    "       'VEHICLE_YEAR', 'VEHICLE_DEFECT', 'VEHICLE_TYPE',\n",
    "       'MANEUVER', 'OCCUPANT_CNT', \n",
    "       'FIRST_CONTACT_POINT', 'PERSON_TYPE','SEX',\n",
    "       'AGE', 'AIRBAG_DEPLOYED', 'EJECTION', 'INJURY_CLASSIFICATION','DRIVER_VISION',\n",
    "       'PHYSICAL_CONDITION', 'Crash_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to drop columns with lots of missing values\n",
    "pd.isnull(df_driver).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe with the new columns\n",
    "df_driver = df_driver[new_columns]\n",
    "#check for nulls\n",
    "pd.isnull(df_driver).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping missing values\n",
    "df_driver.dropna(axis=0, subset=['LATITUDE'], inplace =True)\n",
    "df_driver.dropna(axis=0, subset=['LONGITUDE'], inplace =True)\n",
    "df_driver.dropna(axis=0, subset=['MODEL'], inplace =True)\n",
    "df_driver.dropna(axis=0, subset=['MAKE'], inplace =True)\n",
    "df_driver.dropna(axis=0, subset=['FIRST_CONTACT_POINT'], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df_driver).sum().sort_values(ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_driver.INJURIES_FATAL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_driver.AGE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_driver.SEX.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_driver.VEHICLE_YEAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_driver.VEHICLE_YEAR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling nulls for AGE, SEX, and VEHICLE_YEAR\n",
    "df_driver = df_driver[(df_driver.VEHICLE_YEAR>=1970) & (df_driver.VEHICLE_YEAR <=2021)]\n",
    "df_driver.AGE.replace({np.NAN: df_driver.AGE.median()},inplace=True)\n",
    "df_driver.SEX.replace({np.NAN : 'X'},inplace=True)\n",
    "# Reassigning values for INJURIES FATAL\n",
    "df_driver.INJURIES_FATAL.replace({0.0:0, 1.0:1, 2.0:1, 3.0:1, 4.0:1}, inplace=True)\n",
    "df_driver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_driver.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_driver.hist(figsize=(20,20), bins='auto');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns we do not need\n",
    "columns_to_drop = ['CRASH_RECORD_ID','CRASH_DATE_x','INJURIES_TOTAL','INJURIES_INCAPACITATING',\n",
    "                   'INJURIES_NON_INCAPACITATING','INJURIES_REPORTED_NOT_EVIDENT','MAKE','MOST_SEVERE_INJURY',\n",
    "                   'MODEL','VEHICLE_YEAR','OCCUPANT_CNT','PERSON_TYPE',\n",
    "                   'INJURY_CLASSIFICATION','CRASH_TYPE','LONGITUDE','LATITUDE','Crash_year','CRASH_MONTH']\n",
    "\n",
    "df_driver = df_driver.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_driver.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_driver.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_driver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_driver.PRIM_CONTRIBUTORY_CAUSE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subsetting df where primary contributory cause is determined\n",
    "df_driver = df_driver[df_driver.PRIM_CONTRIBUTORY_CAUSE != 'UNABLE TO DETERMINE']\n",
    "df_driver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_driver.SEC_CONTRIBUTORY_CAUSE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subsetting df where Secondary contributory cause is determined and applicable\n",
    "df_driver = df_driver[(df_driver.SEC_CONTRIBUTORY_CAUSE != 'UNABLE TO DETERMINE')]\n",
    "df_driver = df_driver[(df_driver.SEC_CONTRIBUTORY_CAUSE != 'NOT APPLICABLE')]\n",
    "df_driver.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_driver.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to model\n",
    "features = ['AGE', 'CRASH_HOUR','CRASH_DAY_OF_WEEK', 'POSTED_SPEED_LIMIT','PRIM_CONTRIBUTORY_CAUSE',\n",
    "           'WEATHER_CONDITION','LIGHTING_CONDITION','TRAFFIC_CONTROL_DEVICE','DRIVER_VISION',\n",
    "           'PHYSICAL_CONDITION','ROADWAY_SURFACE_COND','VEHICLE_DEFECT','EJECTION','INJURIES_FATAL']\n",
    "test_df = df_driver[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_df.drop('INJURIES_FATAL',axis=1)\n",
    "y = test_df.INJURIES_FATAL\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Ohe-ing Train set\n",
    "X_train_cat = X_train.select_dtypes('object')\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums_train = ohe.fit_transform(X_train_cat)\n",
    "dums_train_df = pd.DataFrame(dums_train,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_train_cat.index)\n",
    "\n",
    "nums_train_df = X_train.select_dtypes(['int64','float64'])\n",
    "\n",
    "X_train_clean = pd.concat([nums_train_df, dums_train_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ohe-ing Test set\n",
    "X_test_cat = X_test.select_dtypes('object')\n",
    "\n",
    "dums_test = ohe.transform(X_test_cat)\n",
    "dums_test_df = pd.DataFrame(dums_test,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_test_cat.index)\n",
    "\n",
    "nums_test_df = X_test.select_dtypes(['int64','float64'])\n",
    "\n",
    "X_test_clean = pd.concat([nums_test_df, dums_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid = {'max_leaf_nodes': list(range(2, 10)), \n",
    "             'min_samples_split': [2, 3, 4],\n",
    "             'max_depth': [5, 6, 7, 8, 9],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search = GridSearchCV(tree, tree_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree_grid_search.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search.best_estimator_.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_cv_df = pd.DataFrame(tree_grid_search.cv_results_)\n",
    "tree_cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = tree_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train_clean.shape[1]\n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train_clean.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(best_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "# n_estimators = [100,150,200]\n",
    "\n",
    "# The number of features to consider when looking for the best split\n",
    "max_features = ['sqrt', 'log2']\n",
    "\n",
    "# function to measure the quality of a split\n",
    "criteria = ['gini', 'entropy']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "forrest_grid = {'max_features': max_features, \n",
    "                'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_grid_search = GridSearchCV(estimator=forest, param_grid=forrest_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_grid_search.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrest_grid_search.best_estimator_.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest = forrest_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(best_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest_cv_df = pd.DataFrame(forrest_grid_search.cv_results_)\n",
    "forest_cv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting categorical and numeric features from train and test set\n",
    "X_train_cat = X_train.select_dtypes('object')\n",
    "X_test_cat = X_test.select_dtypes('object')\n",
    "nums_train = X_train.select_dtypes(['int64','float64'])\n",
    "nums_test = X_test.select_dtypes(['int64','float64'])\n",
    "\n",
    "# One Hot Encoding the categoricals\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums_train = ohe.fit_transform(X_train_cat)\n",
    "dums_train_df = pd.DataFrame(dums_train,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_train_cat.index)\n",
    "\n",
    "dums_test = ohe.transform(X_test_cat)\n",
    "dums_test_df = pd.DataFrame(dums_test,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_test_cat.index)\n",
    "# Scaling the Numerics\n",
    "scaler = StandardScaler()\n",
    "\n",
    "nums_train_scaled = scaler.fit_transform(nums_train)\n",
    "nums_train_df = pd.DataFrame(nums_train_scaled,\n",
    "                       columns=nums_train.columns,\n",
    "                       index=nums_train.index)\n",
    "\n",
    "nums_test_scaled = scaler.transform(nums_test)\n",
    "nums_test_df = pd.DataFrame(nums_test_scaled,\n",
    "                       columns=nums_test.columns,\n",
    "                       index=nums_test.index)\n",
    "\n",
    "# Scaled and Encoded train and test data\n",
    "X_train_scaled = pd.concat([nums_train_df, dums_train_df], axis=1)\n",
    "X_test_scaled = pd.concat([nums_test_df, dums_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create params_grid for KNeighborsClassifier  \n",
    "knn_grid = {'n_neighbors': [3, 5, 7, 9, 11, 21],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "# create grid search \n",
    "knn_grid = GridSearchCV(knn, knn_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit x_train and y_train to grid \n",
    "knn_grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe combination of best params \n",
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_df = pd.DataFrame(knn_grid.cv_results_)\n",
    "knn_cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_estimator_.score(scaled_data_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = knn_grid.best_estimator_.predict(scaled_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
